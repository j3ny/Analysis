{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import bigfloat\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import seaborn as sns\n",
    "#import matplotlib.mlab as mlab\n",
    "#import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sh import RNAfold, RNAcofold\n",
    "\n",
    "PARAMFILE = '/usr/share/ViennaRNA/dna_mathews2004.par'\n",
    "\n",
    "#sns.set_style(\"whitegrid\", {\"font.family\": \"DejaVu Sans\"})\n",
    "#sns.set_context(\"poster\")\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fold(seq1, seq2='', prog=RNAcofold, RNA=True):\n",
    "    seq = str(seq1) if not seq2 else '%s&%s' % (seq1,seq2)\n",
    "    out = prog(_in=seq, noPS=True) if RNA else prog(_in=seq, noPS=True, noconv=True, dangles=0, P=PARAMFILE)\n",
    "    seq, fold, _ = out.split('\\n')\n",
    "    structure = str(fold.split()[0])\n",
    "    energy = float(fold.partition(' ')[2][1:-1].strip())\n",
    "    return structure, energy\n",
    "\n",
    "def complement(s): \n",
    "    basecomplement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'} \n",
    "    letters = list(s) \n",
    "    letters = [basecomplement[base] for base in letters] \n",
    "    return ''.join(letters)\n",
    "def revcom(s):\n",
    "    return complement(s[::-1])\n",
    "\n",
    "def read_scaffold(filename):\n",
    "    f = open(filename, 'r')\n",
    "    return f.readline().strip()\n",
    "\n",
    "def read_staples(filename):\n",
    "    f = open(filename, 'r')\n",
    "    staples = []\n",
    "    for line in f:\n",
    "        arms = line.strip().split('|')\n",
    "        staples.append(arms) \n",
    "    return staples\n",
    "\n",
    "def scan_staple(staple):\n",
    "    data = []\n",
    "    for arm in staple:\n",
    "        data.append((arm, scan_arm(arm)))\n",
    "    return data\n",
    "\n",
    "def scan_arm(arm_sequence):  \n",
    "    #sliding window over scaffold\n",
    "    arm_data = []\n",
    "    for i in range(len(scaffold) - len(arm_sequence) + 1):\n",
    "        target = scaffold[i:i+len(arm_sequence)]\n",
    "        structure, energy = fold(arm_sequence, target, RNA=False)#[1]\n",
    "        hamming = hamming_distance(revcom(arm_sequence), target)\n",
    "        levenshtein = levenshtein_dist(revcom(arm_sequence), target)\n",
    "        #print arm_sequence, target, mismatches\n",
    "        arm_data.append((energy, hamming, levenshtein, target, structure))\n",
    "        #print (energy, hamming, levenshtein, target, structure)\n",
    "    #consider only local minima sites\n",
    "    local_min = []\n",
    "    for i in range(len(arm_data)):\n",
    "        e_prev = arm_data[i-1][0] if i-1>0 else 0.0\n",
    "        e = arm_data[i][0]\n",
    "        e_next = arm_data[i+1][0] if i+1<len(arm_data) else 0.0\n",
    "        if e < e_prev and e <= e_next:\n",
    "            local_min.append(arm_data[i])\n",
    "    sorted_by_energy = sorted(local_min, key=lambda tup: tup[0])\n",
    "    return arm_data\n",
    "    #return sorted_by_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n",
      "0\n",
      "ACGTACGT\n"
     ]
    }
   ],
   "source": [
    "def levenshtein_dist(source, target):\n",
    "    if len(source) < len(target):\n",
    "        return levenshtein(target, source)\n",
    "    # So now we have len(source) >= len(target).\n",
    "    if len(target) == 0:\n",
    "        return len(source)\n",
    "    # We call tuple() to force strings to be used as sequences\n",
    "    # ('c', 'a', 't', 's') - numpy uses them as values by default.\n",
    "    source = np.array(tuple(source))\n",
    "    target = np.array(tuple(target))\n",
    "    # We use a dynamic programming algorithm, but with the\n",
    "    # added optimization that we only need the last two rows\n",
    "    # of the matrix.\n",
    "    previous_row = np.arange(target.size + 1)\n",
    "    for s in source:\n",
    "        # Insertion (target grows longer than source):\n",
    "        current_row = previous_row + 1\n",
    "        # Substitution or matching:\n",
    "        # Target and source items are aligned, and either\n",
    "        # are different (cost of 1), or are the same (cost of 0).\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                np.add(previous_row[:-1], target != s))\n",
    "        # Deletion (target grows shorter than source):\n",
    "        current_row[1:] = np.minimum(\n",
    "                current_row[1:],\n",
    "                current_row[0:-1] + 1)\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "def hamming_distance(source, target):\n",
    "    assert len(source) == len(target)\n",
    "    count = 0\n",
    "    for p, t in zip(source, target):\n",
    "        count += 1 if p != t else 0\n",
    "    return count\n",
    "\n",
    "print hamming_distance('AAACGCGC', 'AAAGCGCG')\n",
    "print levenshtein_dist('AAACGCGC', 'AAAGCGCG')\n",
    "print levenshtein_dist(revcom('ACGTACGT'), 'ACGTACGT')\n",
    "print revcom('ACGTACGT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Energy Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def analyze(scaffold, staples, filename):\n",
    "    with open(filename, 'w') as output:  \n",
    "        for i, staple in enumerate(staples[:1]):\n",
    "            data = scan_staple(staple)\n",
    "            for arm, arm_data in data:\n",
    "                output.write(arm + '\\n')\n",
    "                for energy, hamming, levenshtein, target, structure in arm_data:\n",
    "                    output.write(\"{},{},{},{},{}\\n\".format(energy, hamming, levenshtein, target, structure))\n",
    "\n",
    "path = 'data/raw/sequences/M13_medium/'\n",
    "scaffold_filename = path + 'scaffold.txt'\n",
    "staples_filename = path + 'DXstaples.txt'\n",
    "\n",
    "scaffold = read_scaffold(scaffold_filename)\n",
    "staples = read_staples(staples_filename)\n",
    "\n",
    "analyze(scaffold, staples, 'data/verification/M13_medium_raw.csv')\n",
    "\n",
    "path = 'data/raw/sequences/DBS_medium/'\n",
    "scaffold_filename = path + 'scaffold.txt'\n",
    "staples_filename = path + 'DXstaples.txt'\n",
    "\n",
    "scaffold = read_scaffold(scaffold_filename)\n",
    "staples = read_staples(staples_filename)\n",
    "\n",
    "analyze(scaffold, staples, 'data/verification/DBS_medium_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Conversion to probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "filename_DB = 'DeBruijn_alpha.json'\n",
    "filename_pUC19 = 'pUC19_alpha.json'\n",
    "filename_M13 = 'M13_square.json'\n",
    "filename_DB7k = 'DB_7k_square.json'\n",
    "\n",
    "#ids, sequences, energies\n",
    "#_, _, energies_DB = read_data(path + filename_DB)\n",
    "#_, _, energies_pUC19 = read_data(path + filename_pUC19)\n",
    "#_, _, energies_M13 = read_data(path + filename_M13)\n",
    "\n",
    "_, _, energies_DB_short = read_data(path + filename_DB, short=True)\n",
    "_, _, energies_pUC19_short = read_data(path + filename_pUC19, short=True)\n",
    "_, _, energies_M13_short = read_data(path + filename_M13, short=True)\n",
    "_, _, energies_DB7k_short = read_data(path + filename_DB7k, short=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def read_data(filename, short=False):\n",
    "#    json_data = open(filename, 'r').read()\n",
    "#    raw_data = json.loads(json_data)\n",
    "#    seq = []\n",
    "#    seq_id = []\n",
    "#    energy = []\n",
    "#    for k1, v1 in raw_data.iteritems():\n",
    "#        if k1 == \"name\":\n",
    "#            continue\n",
    "#        stp_i = int(k1)\n",
    "#        staple = v1\n",
    "#        #print str(stp_i) + ' ' + v1['staple_sequence']\n",
    "#        for k2, v2 in staple.iteritems():\n",
    "#            if not k2.isdigit():\n",
    "#                continue\n",
    "#            arm_i = k2\n",
    "#            arm = v2\n",
    "#            #if short and len(arm['sequence']) > 8:\n",
    "#            #    continue\n",
    "#            dG = arm['dG']\n",
    "#            min_dG = float(arm['min_dG'])\n",
    "#            seq.append(arm['sequence'])\n",
    "#            seq_id.append('stp_' + str(stp_i) + '_' + str(arm_i))\n",
    "#            local_min = []\n",
    "#            for i in range(len(dG)-1):\n",
    "#                if dG[i] < dG[i-1] and dG[i] <= dG[i+1]:\n",
    "#                    local_min.append(float(dG[i]))\n",
    "#            sorted_by_energy = sorted(local_min)\n",
    "#            energy.append(numpy.array(sorted_by_energy))\n",
    "#    return seq_id, seq, energy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
